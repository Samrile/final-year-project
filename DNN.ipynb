{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b972a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f08f3cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      patterns        intent\n",
      "0          yes  accept_quest\n",
      "1         sure  accept_quest\n",
      "2    of course  accept_quest\n",
      "3  I will help  accept_quest\n",
      "4  count me in  accept_quest\n",
      "\n",
      "Lengths of each category:\n",
      "ACCEPT QUEST: 66\n",
      "DECLINE QUEST: 69\n",
      "ASK INFORMATION: 65\n",
      "EXIT GAME: 68\n",
      "Total rows in df: 268\n",
      "Number of patterns: 268\n",
      "Number of intent labels: 268\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"patterns\": [\n",
    "        # ACCEPT QUEST (66 patterns)\n",
    "        \"yes\", \"sure\", \"of course\", \"I will help\", \"count me in\", \"I accept\", \"letâ€™s go\", \"I'm ready\",\n",
    "        \"absolutely\", \"for the kingdom\", \"I'll do it\", \"consider it done\", \"why not\", \"ready to serve\",\n",
    "        \"I'll take the quest\", \"I'm on it\", \"you can trust me\", \"time to begin\", \"let's start\", \"no problem\",\n",
    "        \"happy to help\", \"I'll join\", \"my honor\", \"I'm with you\", \"sign me up\", \"let's make history\",\n",
    "        \"I volunteer\", \"I shall help\", \"I'll take part\", \"on my way\", \"yes sir\", \"I'm in\", \"with pleasure\",\n",
    "        \"yes my lord\", \"I'll try my best\", \"ready for duty\", \"I'll fight\", \"I pledge my help\", \"I'll take the task\",\n",
    "        \"I'm committed\", \"where do I sign up\", \"lead the way\", \"I'm yours to command\", \"let the adventure begin\",\n",
    "        \"I'm up for it\", \"bring it on\", \"I can handle it\", \"alright\", \"affirmative\", \"proceed\",\n",
    "        \"understood, I accept\", \"it would be my honor\", \"I'm game\", \"send me in\", \"I'll see it through\",\n",
    "        \"I stand with you\", \"tell me where to go\", \"show me the path\", \"I won't let you down\", \"my blade is yours\",\n",
    "        \"let's ride\", \"definitely\", \"I'm onboard\", \"sounds good\", \"I've got this\", \"I'm ready to fight\",\n",
    "\n",
    "        # DECLINE QUEST (69 patterns)\n",
    "        \"no\", \"not now\", \"maybe later\", \"I refuse\", \"sorry not interested\", \"not today\", \"I canâ€™t\", \"too risky\",\n",
    "        \"no way\", \"Iâ€™m busy\", \"find someone else\", \"Iâ€™m not ready\", \"this isnâ€™t for me\", \"Iâ€™ll pass\", \"not my job\",\n",
    "        \"leave me alone\", \"I donâ€™t want to\", \"not my problem\", \"forget it\", \"I'm tired\", \"no interest\",\n",
    "        \"perhaps another time\", \"no chance\", \"not happening\", \"I decline\", \"too dangerous\", \"not my duty\",\n",
    "        \"this sounds bad\", \"Iâ€™ll skip it\", \"not worth it\", \"no thanks\", \"Iâ€™d rather not\", \"I'll sit this one out\",\n",
    "        \"sorry, no\", \"I have no time\", \"thatâ€™s impossible\", \"I canâ€™t help\", \"no point\", \"nope\",\n",
    "        \"Iâ€™ll stay out of it\", \"absolutely not\", \"I have other plans\", \"I must decline\", \"I am unable\",\n",
    "        \"my apologies\", \"don't count on me\", \"I'm not the one you're looking for\", \"I respectfully decline\",\n",
    "        \"I can't commit\", \"I'm unavailable\", \"I have a prior engagement\", \"I'm afraid I can't\",\n",
    "        \"that's a hard pass\", \"not in a million years\", \"I need a break\", \"this is beyond my abilities\",\n",
    "        \"I'm done for the day\", \"I'm not skilled enough\", \"I'll have to say no\", \"I won't do it\",\n",
    "        \"I am unwilling\", \"I'm sorry, I cannot\", \"I cannot fulfill this request\", \"i have to say no\",\n",
    "        \"I must say no\", \"negative\", \"reject\", \"I abstain\", \"I object\",\n",
    "\n",
    "        # ASK INFORMATION (65 patterns)\n",
    "        \"tell me more about history\", \"who was the king\", \"what happened in the past\", \"help me\", \"what should I do\",\n",
    "        \"I need guidance\", \"can you explain\", \"teach me\", \"I want to learn\", \"tell me the story\", \"how did it begin\",\n",
    "        \"what is my mission\", \"what do you mean\", \"please explain\", \"give me more info\", \"what happened here\",\n",
    "        \"why did it happen\", \"how did they win\", \"can you elaborate\", \"I want to know more\", \"who built this place\",\n",
    "        \"when did it start\", \"how long ago was it\", \"whatâ€™s the reason\", \"help me understand\", \"who fought in the war\",\n",
    "        \"what is the history\", \"what does this mean\", \"what should I know\", \"give me a hint\", \"tell me what to do\",\n",
    "        \"where am I\", \"who ruled this land\", \"how did the empire fall\", \"whatâ€™s the backstory\", \"why is this important\",\n",
    "        \"can you tell me more\", \"please guide me\", \"Iâ€™m confused\", \"how do I continue\", \"what are the rules\",\n",
    "        \"what is the objective\", \"how does it work\", \"where do I go next\", \"what is this place\", \"what are the risks\",\n",
    "        \"who is the enemy\", \"what's the reward\", \"is there a map\", \"how much time do I have\", \"what's the current situation\",\n",
    "        \"what equipment do I need\", \"can you give me details\", \"what should I look for\", \"where can I find them\",\n",
    "        \"who are you\", \"what is your name\", \"what is the lore\", \"can I ask a question\", \"clarify this for me\",\n",
    "        \"what is that thing\", \"what am I looking at\", \"explain the objective\", \"what's the catch\", \"what's the next step\",\n",
    "\n",
    "        # EXIT GAME (61 patterns)\n",
    "        \"quit\", \"exit\", \"leave game\", \"goodbye\", \"Iâ€™m done\", \"see you\", \"end game\", \"bye\", \"thatâ€™s enough\",\n",
    "        \"close the game\", \"stop playing\", \"Iâ€™m leaving\", \"return to menu\", \"log out\", \"no more\", \"time to rest\",\n",
    "        \"Iâ€™m out\", \"shut down\", \"end session\", \"farewell\", \"take care\", \"game over\", \"until next time\",\n",
    "        \"see you later\", \"thatâ€™s it\", \"finish game\", \"enough for today\", \"letâ€™s stop\", \"done playing\",\n",
    "        \"exit mission\", \"wrap it up\", \"I quit\", \"bye bye\", \"Iâ€™ll be back later\", \"good night\", \"exit story\",\n",
    "        \"Iâ€™m finished\", \"this is over\", \"return back\", \"leave quest\", \"close application\", \"terminate game\",\n",
    "        \"i need to go\", \"save and quit\", \"let me out\", \"end this\", \"i have to leave\", \"stop now\",\n",
    "        \"time to log off\", \"i'm retiring\", \"good day\", \"iâ€™m signing off\", \"i must depart\", \"i'm done with this\",\n",
    "        \"end program\", \"turn off\", \"iâ€™ll be seeing you\", \"i'm turning off the game\", \"that'll do\",\n",
    "        \"halt the game\", \"i'm done playing\", \"i'm calling it a day\", \"i'm taking a break\",\n",
    "        \"switch off\", \"iâ€™m powering down\", \"need to disconnect\", \"i'm logging out\", \"i'm signing out\"\n",
    "    ],\n",
    "    \"intent\": (\n",
    "        [\"accept_quest\"] * 66 +\n",
    "        [\"decline_quest\"] * 69 +\n",
    "        [\"ask_information\"] * 65 +\n",
    "        [\"exit_game\"] * 68\n",
    "    )\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "print(df.head())\n",
    "print(\"\\nLengths of each category:\")\n",
    "print(\"ACCEPT QUEST:\", 66)\n",
    "print(\"DECLINE QUEST:\", 69)\n",
    "print(\"ASK INFORMATION:\", 65)\n",
    "print(\"EXIT GAME:\", 68)\n",
    "print(\"Total rows in df:\", len(df))\n",
    "# Suppose your full lists are still in data\n",
    "patterns = data[\"patterns\"]\n",
    "intent = data[\"intent\"]\n",
    "\n",
    "print(\"Number of patterns:\", len(patterns))\n",
    "print(\"Number of intent labels:\", len(intent))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0edd8a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size:  265\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "# for splitting data ;)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"patterns\"], df[\"intent\"], test_size=0.2, random_state=42)\n",
    "\n",
    "# to encode labels ;)\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_enc = label_encoder.fit_transform(y_train)\n",
    "y_test_enc = label_encoder.transform(y_test)\n",
    "\n",
    "# for vectorizeing text\n",
    "vectorizer = TextVectorization(output_mode= 'int', output_sequence_length= 10)\n",
    "vectorizer.adapt(X_train)\n",
    "\n",
    "vocab_size = len(vectorizer.get_vocabulary())\n",
    "print(\"Vocabulary Size: \",vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2650e2e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ text_vectorization              â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>)             â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooling1d        â”‚ ?                      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ text_vectorization              â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
       "â”‚ (\u001b[38;5;33mTextVectorization\u001b[0m)             â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooling1d        â”‚ ?                      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    vectorizer,\n",
    "    layers.Embedding(input_dim=vocab_size, output_dim=16, mask_zero=True),\n",
    "    layers.GlobalAveragePooling1D(),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5b3d55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.2710 - loss: 1.3846 - val_accuracy: 0.3333 - val_loss: 1.3809\n",
      "Epoch 2/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4393 - loss: 1.3771 - val_accuracy: 0.2963 - val_loss: 1.3780\n",
      "Epoch 3/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5794 - loss: 1.3703 - val_accuracy: 0.3889 - val_loss: 1.3743\n",
      "Epoch 4/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6308 - loss: 1.3626 - val_accuracy: 0.4444 - val_loss: 1.3687\n",
      "Epoch 5/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6776 - loss: 1.3536 - val_accuracy: 0.4630 - val_loss: 1.3630\n",
      "Epoch 6/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7336 - loss: 1.3434 - val_accuracy: 0.5185 - val_loss: 1.3556\n",
      "Epoch 7/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7617 - loss: 1.3308 - val_accuracy: 0.5370 - val_loss: 1.3470\n",
      "Epoch 8/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7804 - loss: 1.3170 - val_accuracy: 0.5370 - val_loss: 1.3364\n",
      "Epoch 9/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8131 - loss: 1.3006 - val_accuracy: 0.5556 - val_loss: 1.3254\n",
      "Epoch 10/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8411 - loss: 1.2820 - val_accuracy: 0.5556 - val_loss: 1.3122\n",
      "Epoch 11/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8645 - loss: 1.2609 - val_accuracy: 0.5741 - val_loss: 1.2980\n",
      "Epoch 12/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8785 - loss: 1.2374 - val_accuracy: 0.5741 - val_loss: 1.2817\n",
      "Epoch 13/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8785 - loss: 1.2106 - val_accuracy: 0.5926 - val_loss: 1.2648\n",
      "Epoch 14/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8785 - loss: 1.1811 - val_accuracy: 0.5926 - val_loss: 1.2462\n",
      "Epoch 15/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8832 - loss: 1.1489 - val_accuracy: 0.5741 - val_loss: 1.2253\n",
      "Epoch 16/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9019 - loss: 1.1127 - val_accuracy: 0.5926 - val_loss: 1.2049\n",
      "Epoch 17/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9065 - loss: 1.0740 - val_accuracy: 0.5741 - val_loss: 1.1828\n",
      "Epoch 18/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9112 - loss: 1.0333 - val_accuracy: 0.5741 - val_loss: 1.1599\n",
      "Epoch 19/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9065 - loss: 0.9900 - val_accuracy: 0.6296 - val_loss: 1.1358\n",
      "Epoch 20/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9112 - loss: 0.9441 - val_accuracy: 0.6667 - val_loss: 1.1114\n",
      "Epoch 21/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9112 - loss: 0.8973 - val_accuracy: 0.6667 - val_loss: 1.0865\n",
      "Epoch 22/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9206 - loss: 0.8500 - val_accuracy: 0.6667 - val_loss: 1.0612\n",
      "Epoch 23/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9299 - loss: 0.8009 - val_accuracy: 0.6852 - val_loss: 1.0373\n",
      "Epoch 24/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9346 - loss: 0.7536 - val_accuracy: 0.6852 - val_loss: 1.0128\n",
      "Epoch 25/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9346 - loss: 0.7058 - val_accuracy: 0.6852 - val_loss: 0.9896\n",
      "Epoch 26/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9346 - loss: 0.6596 - val_accuracy: 0.6852 - val_loss: 0.9680\n",
      "Epoch 27/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9393 - loss: 0.6149 - val_accuracy: 0.6852 - val_loss: 0.9476\n",
      "Epoch 28/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9393 - loss: 0.5719 - val_accuracy: 0.6852 - val_loss: 0.9287\n",
      "Epoch 29/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9393 - loss: 0.5318 - val_accuracy: 0.6852 - val_loss: 0.9115\n",
      "Epoch 30/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9439 - loss: 0.4930 - val_accuracy: 0.6852 - val_loss: 0.8944\n",
      "Epoch 31/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9439 - loss: 0.4578 - val_accuracy: 0.6852 - val_loss: 0.8795\n",
      "Epoch 32/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9439 - loss: 0.4251 - val_accuracy: 0.6852 - val_loss: 0.8668\n",
      "Epoch 33/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9439 - loss: 0.3946 - val_accuracy: 0.7037 - val_loss: 0.8549\n",
      "Epoch 34/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9486 - loss: 0.3665 - val_accuracy: 0.7037 - val_loss: 0.8446\n",
      "Epoch 35/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9533 - loss: 0.3408 - val_accuracy: 0.6852 - val_loss: 0.8356\n",
      "Epoch 36/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9533 - loss: 0.3172 - val_accuracy: 0.6852 - val_loss: 0.8276\n",
      "Epoch 37/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9579 - loss: 0.2955 - val_accuracy: 0.6852 - val_loss: 0.8213\n",
      "Epoch 38/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9626 - loss: 0.2760 - val_accuracy: 0.7037 - val_loss: 0.8158\n",
      "Epoch 39/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9673 - loss: 0.2578 - val_accuracy: 0.7037 - val_loss: 0.8105\n",
      "Epoch 40/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9720 - loss: 0.2412 - val_accuracy: 0.7037 - val_loss: 0.8075\n",
      "Epoch 41/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9720 - loss: 0.2262 - val_accuracy: 0.7037 - val_loss: 0.8053\n",
      "Epoch 42/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9720 - loss: 0.2120 - val_accuracy: 0.7037 - val_loss: 0.8021\n",
      "Epoch 43/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9766 - loss: 0.1988 - val_accuracy: 0.7037 - val_loss: 0.8011\n",
      "Epoch 44/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9860 - loss: 0.1871 - val_accuracy: 0.7037 - val_loss: 0.8003\n",
      "Epoch 45/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9860 - loss: 0.1762 - val_accuracy: 0.7037 - val_loss: 0.7995\n",
      "Epoch 46/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9907 - loss: 0.1658 - val_accuracy: 0.7037 - val_loss: 0.7995\n",
      "Epoch 47/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9907 - loss: 0.1567 - val_accuracy: 0.7222 - val_loss: 0.8006\n",
      "Epoch 48/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9907 - loss: 0.1478 - val_accuracy: 0.7222 - val_loss: 0.8017\n",
      "Epoch 49/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9907 - loss: 0.1398 - val_accuracy: 0.7222 - val_loss: 0.8026\n",
      "Epoch 50/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9907 - loss: 0.1323 - val_accuracy: 0.7222 - val_loss: 0.8039\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train.values, # Convert pandas Series to numpy array\n",
    "    y_train_enc,\n",
    "    epochs=50,\n",
    "    validation_data=(X_test.values, y_test_enc) # Convert pandas Series to numpy array\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d3c13caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7222 - loss: 0.8039\n",
      "âœ… Test Accuracy: 72.22%\n",
      "ğŸ“‰ Test Loss: 0.8039\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model performance\n",
    "test_loss, test_accuracy = model.evaluate(X_test.values, y_test_enc)\n",
    "print(f\"âœ… Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "print(f\"ğŸ“‰ Test Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b0f53b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
